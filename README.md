# Hunter-Data-Processing-Project
This project contains a series of Bash scripts used to extract, transform, clean, analyze, and partition job vacancy data from HeadHunter (hh.ru). Each exercise focuses on a specific part of the data pipeline.


## ğŸ“ Project Structure
```
src/
â”œâ”€â”€ ex00/
â”‚ â”œâ”€â”€ hh.json # Raw vacancy data
â”‚ â””â”€â”€ hh.sh # Script to fetch/update the JSON file
â”œâ”€â”€ ex01/
â”‚ â”œâ”€â”€ filter.jq # JQ filter used for data extraction
â”‚ â”œâ”€â”€ hh.csv # Converted CSV data
â”‚ â””â”€â”€ json_to_csv.sh # Converts JSON to CSV
â”œâ”€â”€ ex02/
â”‚ â”œâ”€â”€ hh_sorted.csv # Sorted CSV by defined criteria
â”‚ â””â”€â”€ sorter.sh # Sorting script
â”œâ”€â”€ ex03/
â”‚ â”œâ”€â”€ hh_positions.csv # Cleaned job titles
â”‚ â””â”€â”€ cleaner.sh # Cleans the dataset
â”œâ”€â”€ ex04/
â”‚ â”œâ”€â”€ hh_uniq_positions.csv # Unique job titles with counts
â”‚ â””â”€â”€ counter.sh # Counts occurrences of each position
â”œâ”€â”€ ex05/
â”‚ â”œâ”€â”€ concatenator.sh # Merges multiple CSVs
â”‚ â””â”€â”€ partitioner.sh # Splits CSV into parts
```

## ğŸ› ï¸ Requirements

- Bash
- `jq` (for JSON parsing)
- Standard Unix utilities (`sort`, `uniq`, `cut`, etc.)

To install `jq`:

```bash
sudo apt-get install jq
```
ğŸš€ Usage

Run each step from the src/ directory.
Step 0: Download the data
bash ex00/hh.sh
Step 1: Convert JSON to CSV
bash ex01/json_to_csv.sh
Step 2: Sort the CSV
bash ex02/sorter.sh
Step 3: Clean job titles
bash ex03/cleaner.sh
Step 4: Count unique job titles
bash ex04/counter.sh
Step 5: Concatenate and partition CSVs
bash ex05/concatenator.sh
bash ex05/partitioner.sh

ğŸ“Œ Notes
    Make sure scripts are executable:

chmod +x ex*/*.sh
    Each script outputs a new CSV file to preserve intermediate results.

ğŸ§‘â€ğŸ’» Author

Sevinch Djabbarova

Feel free to connect with me or contribute improvements!
